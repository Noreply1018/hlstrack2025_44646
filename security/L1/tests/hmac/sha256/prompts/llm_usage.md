# 大模型辅助使用记录
## 基本信息

- 模型名称：GPT-5、GPT-5-Codex、Claude-4.5-sunnet、Claude-4-sunnet
- 提供方 / 访问方式：
  - ChatGPT 网页（https://chatgpt.com/）
  - Cursor 客户端
  - VSCode Codex 插件
- 使用日期：2025-10-18 ~ 2025-11-2
- 项目名称：HMAC‑SHA256 算子优化

---

## 使用场景 1
> GPT-5

### 主要用途
#### 1. 利用 GPT-5 推理能力制定优化方向

GPT-5 在本次 HMAC‑SHA256 算子优化中发挥了重要作用，尤其在优化方向制定、微架构方案设计与策略评估方面：

* 推理与分解：结合时序报告与代码结构，定位关键瓶颈在 SHA‑256 轮函数加法链、消息调度 W[t] 扇出、Σ/σ 位运算深度，以及 ipad/opad 预处理与块边界对接路径。
* 设计大方向：建议将 HMAC 流程划分为数据流阶段：`KeyPreprocess`（键预处理与 ipad/opad 生成）、`InnerHash`（K⊕ipad || message 的 SHA‑256）、`OuterHash`（K⊕opad || inner_digest 的 SHA‑256）、`WriteDigest`（输出拼装与字节序转换）。通过阶段化 + `#pragma HLS dataflow` 降低单拍组合深度。

#### 2. 提供多种优化方案并评估有效性

* 多方案提出：轮函数使用 CSA(3:2) 压缩树缩短加法链；64 轮适度/分组展开；Σ/σ 逻辑前移寄存；复制 K 常量 ROM 降低扇出；BRAM 环形缓冲承载消息调度窗口；AXI4‑Stream 背压解耦。
* 有效性评估：基于 `estimated_time_ns`、`slack_ns`、`latency_cycles_verilog` 与 II 对比，确认“CSA + 局部寄存 + 数据流阶段化”对时序提升最显著且资源可控；大规模全展开资源代价过高不取。

#### 3. 支持关键路径分析与深度优化

* 关键路径分析：`W[t] → Σ1(e)+Ch+K[t]+W[t]+h → t1` 与 `Σ0(a)+Maj+t1 → t2`。建议在 Σ/σ 与 Ch/Maj 后插寄存，并以 CSA 将 5 操作数压缩为 2，再进入最终加法，缩短组合链。
* 深度优化建议：移位/旋转统一用 LUT 逻辑并在关键位宽处插寄存；K[t] 常量用 ROM 并复制到热点以降扇出；字节序转换集中在边界阶段，避免干扰轮函数路径。

#### 4. 结合算法与硬件特点定制优化策略

* 硬件特点：器件 `xc7z020-1`（无 URAM），消息调度与小型 FIFO 采用 BRAM/LUTRAM 组合，避免深度 SRL 串联形成长路径；对高扇出控制信号进行本地寄存复制。
* 算法特性：HMAC 需要两次 SHA‑256 调用，复用压缩核心分别驱动内/外哈希，通过阶段化解耦；长消息流式处理，在块边界实施填充与长度编码。

#### 5. 动态调整与反馈优化

* 二次验证与仿真：每轮修改均运行 HLS，读取 `output.json` 指标（`estimated_time_ns`、`slack_ns`、`latency_cycles_verilog`、II、资源）。
* 实时反馈优化：当展开因子提升导致资源激增且收益有限时回退；在 CSA 引入后若 II 升高则增加局部寄存与流量缓冲以恢复 II=1。

---
### 完整 Prompt 内容
```
# Your Role
Windows + Vitis HLS 2024.2 的 HMAC‑SHA256 吞吐/时序优化工程助手

# Your Goal
- 实现/保持 II=1 的同时降低 estimated_time_ns
- 满足：Synth 通过、csim/cosim 通过、资源在可用范围内、功能正确（与参考 HMAC‑SHA256 一致）

# The Scope
- 仅可修改 crypto/HMAC_SHA256/include/hw/ 下头文件
- 禁止改其他任何文件/接口/脚本/目录，不改变对外接口
- 目标器件：xc7z020-1（无 URAM）

# The Baseline
- 以 crypto/HMAC_SHA256/output.json 为准（比较 estimated_time_ns / slack_ns / latency_cycles_verilog / throughput / 资源）

# Your Flow
1) 运行 HLS

cmd.exe /c "D:\\Xilinx\\Vitis_HLS\\2024.2\\settings64.bat && E: && cd E:\\Desktop\\hmac_sha256\\tests && vitis_hls -f run_hls.tcl"

- 失败→查根目录 vitis_hls.log 修正再跑
- 检测到测试向量校验失败→立刻停止并修正
- 通过→运行 python summarize.py（自动解码/校验/汇总）

2) 读取 crypto/HMAC_SHA256/output.json（主），必要时看 .../csynth.rpt（关注 Critical Path/Slack 与 Loop/Module）

---

# Actions 

---

# Constraints & Rollback
- 若出现：Slack<0 / estimated_time_ns 上升 / 吞吐下降 / 功能异常 → 立刻回退本轮

# Your Reference Checks
- estimated_time_ns 逐轮下降；II=1 保持或恢复；资源可控
- 提交最小化 diff 摘要、output.json 关键指标 Δ、以及 csynth.rpt 关键路径前后对比

# Hard Rules
- 频繁执行 Flow 验证代码，重大修改后务必跑 HLS 以免卡死或结论错误
- 只保留有改进的结果，如恶化则回退；优先以适度资源换取时序改进
```
---
### 模型输出摘要

#### 第一次回复：四阶段数据流重构

* 改进内容：将单体实现拆为四阶段数据流：
  1. `KeyPreprocess`：对 K 归一化（>64B 先哈希），生成 `K_ipad`/`K_opad` 并缓存；
  2. `InnerHash`：对 `K_ipad || message` 做 SHA‑256，引入 CSA 压缩树与局部寄存，II=1；
  3. `OuterHash`：对 `K_opad || inner_digest` 做 SHA‑256，复用同一压缩核心；
  4. `WriteDigest`：拼装 256‑bit 输出并做字节序转换；
  各阶段使用 `#pragma HLS dataflow`、`PIPELINE II=1`，消息调度窗口驻留 BRAM，K 常量 ROM 复制至热点以减小扇出。
* 优化结果：estimated 13.20ns → 12.58ns（slack ≈ 0.92ns），II=1 保持；latency_cycles_verilog 小幅增加（边界寄存），吞吐不变；资源：FF 3.8k，LUT 8.1k，BRAM 8。

#### 第二次回复：Σ/σ 前移寄存与背压解耦

* 改进内容：将 Σ/σ 旋转移位前移并寄存；AXI4‑Stream 背压路径插入打一；消息调度入口添加小型 FIFO。
* 结果：estimated 12.58ns → 12.54ns，II=1 保持；关键路径由“t1 加法链”转移到“消息调度 → 轮函数入口”，组合深度缩短。

#### 第三次回复：常量扇出治理与 ROM 分片

* 改进内容：K 常量 ROM 在 `Inner/Outer` 两阶段各自复制，热点子模块再局部复制；
* 结果：estimated 12.54ns → 12.51ns；资源 LUT+3.5%，可控。

---
### 人工审核与采纳情况
#### 1. 采纳并应用到代码中的建议

* 采纳：四阶段数据流、CSA + 局部寄存、背压解耦、K 常量复制、BRAM 窗口化消息调度。
* 验证：estimated 13.20ns → 12.51–12.58ns 区间改善，II=1 保持；功能一致性通过标准向量校验。

#### 2. 经验证未采纳的建议及原因

* 全展开 64 轮：时序可能改善但 LUT/FF 布线压力过大，不成比例。
* 双核并行（Inner/Outer 各一核）：面积近翻倍，系统带宽限制下吞吐收益有限。

#### 3. 是否进行了二次验证或仿真测试

* 是。每轮运行 HLS 并解析 `output.json`，核对 `estimated_time_ns/slack_ns/latency_cycles_verilog/II/资源`；对照 RFC 4231 测试向量校验功能。

---

## 使用场景 2
> GPT-5-Codex

### 主要用途
#### 1. 自动化实施与回归保护
* 依据 GPT‑5 的方案，对 `Inner/Outer` 压缩核心、消息调度与阶段化接口进行最小化变更，实现 CSA、局部寄存与 BRAM 窗口。
* 每轮修改后自动运行 HLS，比较 `output.json` 指标；若 estimated 上升、II 回退或功能校验失败，则自动回退至稳定版本。

#### 2. HLS 流程编排与指标采集
* 封装命令：初始化环境、执行 `vitis_hls -f run_hls.tcl`、解析 `output.json`、生成增量 diff 摘要与关键路径对比（`csynth.rpt` 摘要）。
* 监控字段：`estimated_time_ns`、`slack_ns`、`latency_cycles_verilog`、`II`、`FF/LUT/BRAM` 与功能校验结果。

#### 3. 代码变更最小化与可追溯
* 遵守“仅改 crypto/HMAC_SHA256/include/hw/，对外接口不变”的约束；
* 小步提交，聚焦关键路径，便于定位与回滚。

---
### 完整 Prompt 内容
```
# Role
你是 Codex，负责将 GPT‑5 的优化策略最小集成到 HMAC‑SHA256 工程中，并维持自动化 HLS 验证与回退。

# Tasks
- 实施 CSA/寄存/阶段化/ROM 复制等修改；
- 运行 HLS 并解析输出；
- 生成 diff 摘要 + 指标 Δ；
- 条件回退：estimated 上升或功能不符即回退。
```
---
### 模型输出摘要

#### 第一次执行：引入 CSA 与局部寄存
* 变更：在 `t1` 路径加入 3:2 压缩树与一级寄存，Σ/σ 输出前移寄存；消息调度窗口改用 BRAM 环形缓冲；K 常量按阶段复制。
* 结果：estimated 13.20ns → 12.66ns，II=1；资源小幅上升，可控。

#### 第二次执行：阶段化与背压解耦
* 变更：显式 `#pragma HLS dataflow` 分离 `KeyPreprocess/Inner/Outer/WriteDigest`，阶段间以小型 FIFO 解耦；AXI 背压路径打一。
* 结果：estimated 12.66ns → 12.58ns，关键路径缩短。

#### 第三次执行：ROM 分片与热点复制
* 变更：K 常量 ROM 在 `Inner/Outer` 两阶段分片并热点复制；
* 结果：estimated 12.58ns → 12.55ns；LUT+2.1%。

---
### 人工审核与采纳情况
#### 1. 采纳并应用到代码中的建议
* 采纳：自动化流程、条件回退、阶段化与 CSA/寄存实现、ROM 分片复制。

#### 2. 经验证未采纳的建议及原因
* 过度分组展开（每 4 轮）：收益有限且 II 风险升高，未采纳。
* 双核并行：面积代价过大，系统受限于 I/O 带宽，未采纳。

#### 3. 是否进行了二次验证或仿真测试
* 是。每轮执行 HLS 并保存指标快照，失败即回退。

#### 总结
* Codex 在实施与验证闭环方面大幅减少人工开销，确保每次提交可度量、可回退、可追溯。

---

## 使用场景 3
> Claude-4.5-sunnet / Claude-4-sunnet

### 主要用途
#### 1. 规范核对与边界用例枚举
* 对照 FIPS 180‑4（SHA‑256）与 RFC 2104/4231（HMAC）核对实现要点：填充与长度编码、字节序、K 归一化、ipad/opad 处理顺序、分块边界处理。
* 枚举边界用例：空消息、短键/长键（>64B）、多块长消息、非整字节对齐、流式输入背压、奇偶长度交替等。

#### 2. 测试向量与对照验证
* 提供 RFC 4231 标准 HMAC‑SHA256 测试向量及随机回归样例；
* 生成期望摘要并与仿真输出比对，定位大小端/长度域/填充偏移等常见问题。

#### 3. 文档与可读性改进
* 梳理数据路径与阶段职责，输出开发说明与审计清单；
* 为关键宏与函数添加用途描述，降低维护成本。

---
### 完整 Prompt 内容
```
# Role
你是规范与验证顾问。请按照 FIPS 180-4（SHA-256）逐项核对我的实现：
- 填充与长度编码、消息分块、大小端处理是否正确？
- 生成包含空消息、超长消息、多块消息、奇偶长度交替等边界用例；
- 给出参考摘要并和仿真输出逐比特对比；
- 若发现问题，指出最小修改点，并建议把字节序转换统一在输出阶段。

# Output
- 规范核对清单
- 边界用例与期望摘要
- 差异定位与修复建议
```
---
### 模型输出摘要
* 修复：外层 HMAC 拼接的长度编码边界问题（特定长消息末块）。
* 建议：中间摘要字节序转换统一在 `WriteDigest`，避免在轮函数路径引入额外组合逻辑。
* 验证：RFC 4231 的 7 组向量全部通过，新增随机回归 200 例均通过。

---
### 人工审核与采纳情况
#### 1. 采纳并应用到代码中的建议
* 采纳：测试向量集、边界用例清单、字节序/长度域统一收敛策略、文档化改进。

#### 2. 经验证未采纳的建议及原因
* 将所有移位实现统一替换为 DSP：在目标器件上收益不明显且占用宝贵资源，未采纳。

#### 3. 是否进行了二次验证或仿真测试
* 是。每次修改后均进行仿真与向量比对，全部通过后纳入基线。

#### 总结
* Claude 聚焦规范与验证，帮助稳定功能边界与文档化，提升可维护性与审计可读性。

---

## 总结

### 整体贡献度评估
#### 1. 大模型在本项目中的总体贡献占比：约 70%
* GPT‑5：制定优化策略与方向，进行关键路径分析与微架构方案设计。
* GPT‑5‑Codex：代码最小化实现与自动化 HLS 流程编排，闭环验证与回退。
* Claude‑4.x：规范核对、测试向量与文档沉淀。

#### 2. 主要帮助领域：代码优化 / 文档撰写 / 调试分析
* 代码优化：阶段化、CSA/寄存、背压解耦、ROM 分片复制、BRAM 窗口化消息调度。
* 文档撰写：Prompt 规范、变更摘要、指标对照、审计清单。
* 调试分析：指标趋势追踪、关键路径迁移分析、功能边界核验。

#### 3. 人工介入与修正比例：约 30%
* 策略选择与取舍、异常定位与回退决策、资源/时序的最终平衡。

#### 4. 影响与价值
* 结果：estimated_time_ns 由 13.20ns 降至 12.51–12.58ns，II=1 保持；功能通过 RFC 4231 与随机回归；资源在可控范围。
* 价值：在不改外部接口的前提下提升时序，形成可复制的优化套路与自动化流程。

---
### 学习收获

#### 1. 更好地发挥大模型优势：推理型 vs. 实施型
* 推理型（GPT‑5）：擅长方向规划与瓶颈拆解，适合制定“阶段化 + CSA + 扇出治理”的整体框架。
* 实施型（GPT‑5‑Codex）：擅长小步快跑与自动化验证，适合把方案快速落地并保驾回归。

#### 2. 让模型更好理解意图
* 明确目标与硬约束（II=1、器件与目录范围、回退条件）；
* 输出要求结构化（diff 摘要、指标 Δ、关键路径前后对比）。

#### 3. 写好提示词切中关键
* 精准描述问题/期望结果/禁止项；
* 拆分任务步骤，逐轮校验，避免一次性大改致验证成本过高。

---
## 附注

- 请确保填写真实、完整的使用记录。
- 如未使用大模型辅助，请在此文件中注明“本项目未使用大模型辅助”。
- 评审方将参考此记录了解项目的独立性与创新性。

